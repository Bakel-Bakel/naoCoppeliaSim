import gymnasium as gym
import tensorflow as tf
import numpy as np
from stable_baselines.common.policies import MlpPolicy
from stable_baselines import PPO2  # TensorFlow-based PPO
from nao_gym_env import NaoCoppeliaEnv

# âœ… Initialize NAO environment
env = NaoCoppeliaEnv()

# âœ… Train PPO with TensorFlow-based policy
model = PPO2(MlpPolicy, env, verbose=1)

# âœ… Initialize reward tracking
reward_log = []

try:
    print("ðŸš€ Training Started (TensorFlow). Press Ctrl+C to stop safely...")

    # âœ… Training loop
    for _ in range(100000):  # Number of training steps
        obs = env.reset()
        total_reward = 0
        done = False

        while not done:
            action, _ = model.predict(obs)
            obs, reward, done, _, _ = env.step(action)
            total_reward += reward

        reward_log.append(total_reward)  # âœ… Log episode reward

except KeyboardInterrupt:
    print("\nðŸ›‘ Training interrupted. Saving model and rewards...")
    model.save("nao_ppo_tf_model")
    env.close()

    # âœ… Save rewards to file
    np.save("training_rewards.npy", np.array(reward_log))
    print("âœ… Model and reward log saved.")

# âœ… Save trained model and rewards
model.save("nao_ppo_tf_model")
np.save("training_rewards.npy", np.array(reward_log))
env.close()

